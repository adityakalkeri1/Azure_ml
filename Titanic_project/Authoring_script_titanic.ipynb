{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is the authoring script to run the training of LGBM on Azure Machine Learning.\n",
    "\n",
    "Prerequisetes:\n",
    "    \n",
    "    1. Azure Workspace.\n",
    "    2. Titanic dataset from kaggle\n",
    "    3. The kaggle dataset should be stored in a separate folder\n",
    "\n",
    "Steps:\n",
    "    \n",
    "    1. Import Workspace, Experiment, create compute cluster\n",
    "    2. Clean, preprocess and get the dataset nearly ready for the model. Upload the dataset and register it\n",
    "    3. Prepare the RunConfig file : all environment variables (docker, python packages , etc) must be described here. Define run_amlcompute object\n",
    "    4. Prepare a script_params: a dictionary containing all user defined parameters that we need to pass to environment\n",
    "    5. Prepare training script. Prepare ScriptRunConfig. Submit the run\n",
    "    6. Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currently ataset class is not supported by your Linux distribution.\n",
    "#For Linux users, Dataset class is only supported on the following distributions:\n",
    "#Red Hat Enterprise Linux, Ubuntu(Upto ubuntu 16), Fedora, and CentOS.\n",
    "from dotnetcore2 import runtime\n",
    "runtime.version = (\"18\", \"10\", \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, Workspace, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Create Workspace, environment, aml compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config('~/.azureml/config.json')\n",
    "exp = Experiment(workspace = ws, name = 'titanic_lgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "#Firing up compue target\n",
    "vm_size = 'STANDARD_D2_V2'\n",
    "max_nodes = 4\n",
    "cluster_name = 'titanic-cluster'\n",
    "try:\n",
    "    aml_cluster = ComputeTarget(workspace=ws, name=cluster_name)    #Looking for existing compute cluster\n",
    "except ComputeTargetException:\n",
    "    amlconfig = AmlCompute.provisioning_configuration(vm_size=vm_size,  #If none exist, creating a new one\n",
    "                                                     max_nodes = max_nodes)\n",
    "    aml_cluster = ComputeTarget.create(ws, cluster_name, amlconfig)\n",
    "\n",
    "aml_cluster.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2 : Importing Data and cleaning it. Register the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df.drop(['PassengerId'], axis=1, inplace=True)\n",
    "\n",
    "# 'Embarked' is stored as letters, so we will concert it to numbers\n",
    "embarked_encoder = LabelEncoder()\n",
    "embarked_encoder.fit(df['Embarked'].fillna('Null'))\n",
    " \n",
    "# Creating a new column denoting whether someone came alone \n",
    "df['Alone'] = (df['SibSp'] == 0) & (df['Parch'] == 0)\n",
    "\n",
    "# Transform 'Embarked'\n",
    "df['Embarked'].fillna('Null', inplace=True)\n",
    "df['Embarked'] = embarked_encoder.transform(df['Embarked'])\n",
    "\n",
    "# Transform 'Sex'\n",
    "df.loc[df['Sex'] == 'female','Sex'] = 0\n",
    "df.loc[df['Sex'] == 'male','Sex'] = 1\n",
    "df['Sex'] = df['Sex'].astype('int8')\n",
    "\n",
    "# Drop features that seem unusable. Save passenger ids if test\n",
    "df.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to saved dataset\n",
    "data_location = os.path.join('./data', 'titanic_cleaned.csv')\n",
    "\n",
    "#Saving the cleaned data as csv\n",
    "df.to_csv(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Target already exists. Skipping upload for data/titanic_cleaned.csv\n",
      "Target already exists. Skipping upload for data/train.csv\n",
      "Uploaded 0 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_28445fe417894d4181260e6d863eb2a4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this cell, we will upload the dataset to azure 'Datastore'\n",
    "\n",
    "#First, lets get the datastore\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "#Upload the csv to above datastore\n",
    "datastore.upload(src_dir = './data',                  #Source Directory\n",
    "                 target_path = './data')              #Directory in blob storage where data will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', './data/titanic_cleaned.csv')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\",\n",
       "    \"SetColumnTypes\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"9ad18a58-16d7-4318-8249-7c116c98cea1\",\n",
       "    \"name\": \"titanic_cleaned\",\n",
       "    \"version\": 1,\n",
       "    \"workspace\": \"Workspace.create(name='titanic_ws', subscription_id='ea3f69e8-c36f-4fc3-8495-d53f48fcf14a', resource_group='ml_project_titanic')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset from file in blob storage\n",
    "dataset = Dataset.Tabular.from_delimited_files(datastore.path(data_location))\n",
    "\n",
    "#Registering the dataset and creating version\n",
    "dataset.register(workspace = ws, name = 'titanic_cleaned', create_new_version = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3:Prepare Runconfig file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n",
      "'auto_prepare_environment' is deprecated and unused. It will be removed in a future release.\n",
      "'auto_prepare_environment' is deprecated and unused. It will be removed in a future release.\n"
     ]
    }
   ],
   "source": [
    "runconfig = RunConfiguration()\n",
    "\n",
    "#Configuring environment parameters\n",
    "runconfig.target = aml_cluster\n",
    "\n",
    "runconfig.environment.docker.enabled = True\n",
    "runconfig.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "\n",
    "packages = ['azureml-defaults', 'azureml-contrib-interpret', 'azureml-core', \n",
    "            'azureml-telemetry', 'azureml-interpret', 'sklearn-pandas', 'azureml-dataprep',\n",
    "           'numpy', 'pandas', 'matplotlib', 'seaborn', 'scikit-learn', 'lightgbm', 'umap-learn', 'joblib']\n",
    "\n",
    "runconfig.auto_prepare_environment = True\n",
    "runconfig.environment.python.user_managed_dependencies = False\n",
    "runconfig.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "pip_packages = packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 : Make the scrip params variable, Define Script Run Config, run the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First decide which arguments you want to pass the train.py script. In this example, we will only pass the\n",
    "#Model Hyperparameters \n",
    "script_params = ['--boosting', 'dart',                         \n",
    "    '--learning-rate', '0.05',                     \n",
    "    '--drop-rate', '0.1',                         \n",
    "]                                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: titanic_lgbm_1623203998_d8febb4d\n",
      "Web View: https://ml.azure.com/runs/titanic_lgbm_1623203998_d8febb4d?wsid=/subscriptions/ea3f69e8-c36f-4fc3-8495-d53f48fcf14a/resourcegroups/ml_project_titanic/workspaces/titanic_ws&tid=90e9d100-8173-4458-9c32-166e0ec3eb49\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_6b710428067810f4c9a962d51ac8fb9ed4df47e00b47c5d67e33300ec9cf117f_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2021-06-09T02:03:48Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/titanic_ws/azureml/titanic_lgbm_1623203998_d8febb4d/mounts/workspaceblobstore\n",
      "2021-06-09T02:03:48Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-06-09T02:03:48Z Starting output-watcher...\n",
      "2021-06-09T02:03:48Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-06-09T02:03:49Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-06-09T02:03:49Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_ac35fb6cdf3ca86a7384080e8cc1c2af\n",
      "01bf7da0a88c: Pulling fs layer\n",
      "f3b4a5f15c7a: Pulling fs layer\n",
      "57ffbe87baa1: Pulling fs layer\n",
      "49ff47a72518: Pulling fs layer\n",
      "8bb24fe5debe: Pulling fs layer\n",
      "7361e3efbbd4: Pulling fs layer\n",
      "565f8494b551: Pulling fs layer\n",
      "67c27ed37b8f: Pulling fs layer\n",
      "86831fadece0: Pulling fs layer\n",
      "b440cb7345b3: Pulling fs layer\n",
      "0eeabe958307: Pulling fs layer\n",
      "87113e25cb17: Pulling fs layer\n",
      "abfba0cdd341: Pulling fs layer\n",
      "5f14d71a633b: Pulling fs layer\n",
      "beab623daf69: Pulling fs layer\n",
      "2678269c432e: Pulling fs layer\n",
      "c56daa467726: Pulling fs layer\n",
      "75a520b2f597: Pulling fs layer\n",
      "557fdfc9a6a4: Pulling fs layer\n",
      "795c6094303b: Pulling fs layer\n",
      "0eeabe958307: Waiting\n",
      "87113e25cb17: Waiting\n",
      "abfba0cdd341: Waiting\n",
      "5f14d71a633b: Waiting\n",
      "beab623daf69: Waiting\n",
      "2678269c432e: Waiting\n",
      "c56daa467726: Waiting\n",
      "75a520b2f597: Waiting\n",
      "557fdfc9a6a4: Waiting\n",
      "795c6094303b: Waiting\n",
      "49ff47a72518: Waiting\n",
      "8bb24fe5debe: Waiting\n",
      "7361e3efbbd4: Waiting\n",
      "565f8494b551: Waiting\n",
      "67c27ed37b8f: Waiting\n",
      "86831fadece0: Waiting\n",
      "b440cb7345b3: Waiting\n",
      "f3b4a5f15c7a: Verifying Checksum\n",
      "f3b4a5f15c7a: Download complete\n",
      "57ffbe87baa1: Verifying Checksum\n",
      "57ffbe87baa1: Download complete\n",
      "01bf7da0a88c: Verifying Checksum\n",
      "01bf7da0a88c: Download complete\n",
      "8bb24fe5debe: Verifying Checksum\n",
      "8bb24fe5debe: Download complete\n",
      "7361e3efbbd4: Verifying Checksum\n",
      "7361e3efbbd4: Download complete\n",
      "67c27ed37b8f: Verifying Checksum\n",
      "67c27ed37b8f: Download complete\n",
      "49ff47a72518: Verifying Checksum\n",
      "49ff47a72518: Download complete\n",
      "b440cb7345b3: Verifying Checksum\n",
      "b440cb7345b3: Download complete\n",
      "0eeabe958307: Verifying Checksum\n",
      "0eeabe958307: Download complete\n",
      "565f8494b551: Verifying Checksum\n",
      "565f8494b551: Download complete\n",
      "87113e25cb17: Verifying Checksum\n",
      "87113e25cb17: Download complete\n",
      "abfba0cdd341: Verifying Checksum\n",
      "abfba0cdd341: Download complete\n",
      "86831fadece0: Verifying Checksum\n",
      "86831fadece0: Download complete\n",
      "5f14d71a633b: Download complete\n",
      "beab623daf69: Verifying Checksum\n",
      "beab623daf69: Download complete\n",
      "c56daa467726: Verifying Checksum\n",
      "c56daa467726: Download complete\n",
      "75a520b2f597: Verifying Checksum\n",
      "75a520b2f597: Download complete\n",
      "557fdfc9a6a4: Verifying Checksum\n",
      "557fdfc9a6a4: Download complete\n",
      "795c6094303b: Verifying Checksum\n",
      "795c6094303b: Download complete\n",
      "01bf7da0a88c: Pull complete\n",
      "f3b4a5f15c7a: Pull complete\n",
      "57ffbe87baa1: Pull complete\n",
      "2678269c432e: Verifying Checksum\n",
      "2678269c432e: Download complete\n",
      "49ff47a72518: Pull complete\n",
      "8bb24fe5debe: Pull complete\n",
      "7361e3efbbd4: Pull complete\n",
      "565f8494b551: Pull complete\n",
      "67c27ed37b8f: Pull complete\n",
      "86831fadece0: Pull complete\n",
      "b440cb7345b3: Pull complete\n",
      "0eeabe958307: Pull complete\n",
      "87113e25cb17: Pull complete\n",
      "abfba0cdd341: Pull complete\n",
      "5f14d71a633b: Pull complete\n",
      "beab623daf69: Pull complete\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_6b710428067810f4c9a962d51ac8fb9ed4df47e00b47c5d67e33300ec9cf117f_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2021-06-09T02:05:22.753349] Entering job release\n",
      "[2021-06-09T02:05:23.883825] Starting job release\n",
      "[2021-06-09T02:05:23.885183] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 365\n",
      "[2021-06-09T02:05:23.885630] job release stage : upload_datastore starting...\n",
      "[2021-06-09T02:05:23.887750] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-06-09T02:05:23.887834] job release stage : execute_job_release starting...\n",
      "[2021-06-09T02:05:23.888348] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-06-09T02:05:23.896669] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-06-09T02:05:23.897515] Entering context manager injector.\n",
      "[2021-06-09T02:05:23.899168] job release stage : upload_datastore completed...\n",
      "[2021-06-09T02:05:24.091669] job release stage : execute_job_release completed...\n",
      "[2021-06-09T02:05:24.123765] job release stage : send_run_telemetry starting...\n",
      "[2021-06-09T02:05:24.341390] get vm size and vm region successfully.\n",
      "[2021-06-09T02:05:24.746640] get compute meta data successfully.\n",
      "[2021-06-09T02:05:24.927327] post artifact meta request successfully.\n",
      "[2021-06-09T02:05:24.959282] upload compute record artifact successfully.\n",
      "[2021-06-09T02:05:24.959354] job release stage : send_run_telemetry completed...\n",
      "[2021-06-09T02:05:24.959701] Job release is complete\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: titanic_lgbm_1623203998_d8febb4d\n",
      "Web View: https://ml.azure.com/runs/titanic_lgbm_1623203998_d8febb4d?wsid=/subscriptions/ea3f69e8-c36f-4fc3-8495-d53f48fcf14a/resourcegroups/ml_project_titanic/workspaces/titanic_ws&tid=90e9d100-8173-4458-9c32-166e0ec3eb49\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'titanic_lgbm_1623203998_d8febb4d',\n",
       " 'target': 'titanic-cluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-06-09T02:03:47.314668Z',\n",
       " 'endTimeUtc': '2021-06-09T02:05:33.788758Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '0d40c5bc-56cb-4857-9f25-9704f78a1106',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '9ad18a58-16d7-4318-8249-7c116c98cea1'}, 'consumptionDetails': {'type': 'Reference'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'train_titanic.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--boosting',\n",
       "   'dart',\n",
       "   '--learning-rate',\n",
       "   '0.05',\n",
       "   '--drop-rate',\n",
       "   '0.1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'titanic-cluster',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'Experiment titanic_lgbm Environment',\n",
       "   'version': 'Autosave_2021-06-08T23:41:36Z_3bf1a4f7',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'azureml-contrib-interpret',\n",
       "        'azureml-core',\n",
       "        'azureml-telemetry',\n",
       "        'azureml-interpret',\n",
       "        'sklearn-pandas',\n",
       "        'azureml-dataprep',\n",
       "        'numpy',\n",
       "        'pandas',\n",
       "        'matplotlib',\n",
       "        'seaborn',\n",
       "        'scikit-learn',\n",
       "        'lightgbm',\n",
       "        'umap-learn',\n",
       "        'joblib']}],\n",
       "     'name': 'azureml_b0a54454c5bf8beaf01a59f648b54d44'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210507.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_6b710428067810f4c9a962d51ac8fb9ed4df47e00b47c5d67e33300ec9cf117f_d.txt': 'https://titanicwstorage0ed7384dc.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic_lgbm_1623203998_d8febb4d/azureml-logs/55_azureml-execution-tvmps_6b710428067810f4c9a962d51ac8fb9ed4df47e00b47c5d67e33300ec9cf117f_d.txt?sv=2019-02-02&sr=b&sig=E0n7dPT2JjmEib8jn2CVgYIVOxrx3feQdTH5c3I5BOo%3D&st=2021-06-09T01%3A55%3A35Z&se=2021-06-09T10%3A05%3A35Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_6b710428067810f4c9a962d51ac8fb9ed4df47e00b47c5d67e33300ec9cf117f_d.txt': 'https://titanicwstorage0ed7384dc.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic_lgbm_1623203998_d8febb4d/azureml-logs/65_job_prep-tvmps_6b710428067810f4c9a962d51ac8fb9ed4df47e00b47c5d67e33300ec9cf117f_d.txt?sv=2019-02-02&sr=b&sig=TgGeRZExgFElYLfXGUrWRmx2HkXCJddGyIv5ni5gFs8%3D&st=2021-06-09T01%3A55%3A35Z&se=2021-06-09T10%3A05%3A35Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://titanicwstorage0ed7384dc.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic_lgbm_1623203998_d8febb4d/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=m%2BuT4z7gFDTIAl7xmKxpabM5EZRfn4A3X5naTJcjKPI%3D&st=2021-06-09T01%3A55%3A35Z&se=2021-06-09T10%3A05%3A35Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_6b710428067810f4c9a962d51ac8fb9ed4df47e00b47c5d67e33300ec9cf117f_d.txt': 'https://titanicwstorage0ed7384dc.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic_lgbm_1623203998_d8febb4d/azureml-logs/75_job_post-tvmps_6b710428067810f4c9a962d51ac8fb9ed4df47e00b47c5d67e33300ec9cf117f_d.txt?sv=2019-02-02&sr=b&sig=QxA4V68klMBqinipqV2RGOINqT9qKuyHmNJXfAhk4to%3D&st=2021-06-09T01%3A55%3A35Z&se=2021-06-09T10%3A05%3A35Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://titanicwstorage0ed7384dc.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic_lgbm_1623203998_d8febb4d/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=mM10jYeFtdN30jYQl6l0y72XmWOWCJA1TegM0dvuqEg%3D&st=2021-06-09T01%3A55%3A35Z&se=2021-06-09T10%3A05%3A35Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://titanicwstorage0ed7384dc.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic_lgbm_1623203998_d8febb4d/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=CqSTPCMlNi3NOiuy2J71XWkB37B5Sm9lDaQiGG%2FW3Rg%3D&st=2021-06-09T01%3A55%3A35Z&se=2021-06-09T10%3A05%3A35Z&sp=r',\n",
       "  'logs/azureml/98_azureml.log': 'https://titanicwstorage0ed7384dc.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic_lgbm_1623203998_d8febb4d/logs/azureml/98_azureml.log?sv=2019-02-02&sr=b&sig=KfERq1srBuFx3TbY0XWqxY1OtWRfhl5zrboCEk1EOxQ%3D&st=2021-06-09T01%3A55%3A35Z&se=2021-06-09T10%3A05%3A35Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://titanicwstorage0ed7384dc.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic_lgbm_1623203998_d8febb4d/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=9EYtvhjenlcvxIjD0sMbtShc%2FFeIh887nbAgqIIcCmQ%3D&st=2021-06-09T01%3A55%3A35Z&se=2021-06-09T10%3A05%3A35Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://titanicwstorage0ed7384dc.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic_lgbm_1623203998_d8febb4d/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=1KUbYJJHkcgiA1bjt5ggyumTBVf3oLWAOKhN057297M%3D&st=2021-06-09T01%3A55%3A35Z&se=2021-06-09T10%3A05%3A35Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://titanicwstorage0ed7384dc.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic_lgbm_1623203998_d8febb4d/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=8lkaF%2BkaTbnwvjJiuluF1wHi%2F1FAqniWtJhpJ%2FKsDKs%3D&st=2021-06-09T01%3A55%3A35Z&se=2021-06-09T10%3A05%3A35Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://titanicwstorage0ed7384dc.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic_lgbm_1623203998_d8febb4d/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=IbTkluJ5iYacBD1H4kMc7wBkZ8h4h0QP9g%2FTlCmosKI%3D&st=2021-06-09T01%3A55%3A35Z&se=2021-06-09T10%3A05%3A35Z&sp=r'},\n",
       " 'submittedBy': 'Aditya Kalkeri'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "script = 'train_titanic.py'\n",
    "script_folder = os.getcwd()\n",
    "\n",
    "src = ScriptRunConfig(\n",
    "  source_directory=script_folder,\n",
    "  script=script,\n",
    "  run_config=runconfig,\n",
    "  arguments=script_params)\n",
    "\n",
    "run = exp.submit(src)\n",
    "\n",
    "run.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ml.azure.com/runs/titanic_lgbm_1623203998_d8febb4d?wsid=/subscriptions/ea3f69e8-c36f-4fc3-8495-d53f48fcf14a/resourcegroups/ml_project_titanic/workspaces/titanic_ws&tid=90e9d100-8173-4458-9c32-166e0ec3eb49\n"
     ]
    }
   ],
   "source": [
    "print(run.get_portal_url())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
